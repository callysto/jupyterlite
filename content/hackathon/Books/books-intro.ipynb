{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Callysto.ca Banner](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-top.jpg?raw=true)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/callysto/jupyterlite/blob/main/content/hackathon/Books/books-intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg?sanitize=true\" width=\"123\" height=\"24\" alt=\"Open in Callysto\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Books Introduction\n",
    "\n",
    "## Alice's Adventures in Wonderland\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td> <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e2/John_Tenniel-_Alice%27s_mad_tea_party%2C_colour.jpg\" alt=\"Alice's Tea Party\" style=\"width: 432px;\"/> </td>\n",
    "<td> <img src=\"https://upload.wikimedia.org/wikipedia/en/8/8f/Alice_in_Wonderland_pg41_-_Alice_meets_the_White_Rabbit_-_by_Margaret_Winifred_Tarrant_1916.jpg\" alt=\"Alice Meeting White Rabbit\" style=\"width: 240px;\"/> </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"font-size:8px;\"><a href=\"https://commons.wikimedia.org/wiki/File:John_Tenniel-_Alice%27s_mad_tea_party,_colour.jpg\">John_Tenniel-_Alice%27s_mad_tea_party,_colour.jpg</a></td>\n",
    "<td style=\"font-size:8px;\"><a href=\"https://en.wikipedia.org/wiki/File:Alice_in_Wonderland_pg41_-_Alice_meets_the_White_Rabbit_-_by_Margaret_Winifred_Tarrant_1916.jpg\">Alice_meets_the_White_Rabbit_-_by_Margaret_Winifred_Tarrant_1916.jpg</a></td>\n",
    "</tr>\n",
    "</table>\n",
    "    \n",
    "[Alice's Adventures in Wonderland](https://en.wikipedia.org/wiki/Alice's_Adventures_in_Wonderland) is a popular fiction novel written in 1865 by English author Charles Lutwidge Dodgson.\n",
    "\n",
    "On a regular day you might be reading the book and speculating about what will happen next. However in this hackathon you will encounter some interesting findings about the book while learning some new coding/hacking skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ready\n",
    "\n",
    "This section sets up many things behind the scenes which are required for the rest of this notebook. Most of the code blocks in this section are ready-to-run so you won't have to do any modifications. You don't need to know everything about various tasks being accomplished by the code cell in this section to complete the challenges. However feel free to ask mentors about anything that makes you curious.\n",
    "\n",
    "### Import/Install libraries\n",
    "\n",
    "Run the cell below to import, or download and install required Python libraries. It may take couple of minutes to complete the execution of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install plotly spacy nbformat requests pandas\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "import spacy\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except:\n",
    "    %python -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "print('Setup Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the book from Project Guttenberg\n",
    "\n",
    "**[Project Gutenberg](https://www.gutenberg.org/)** is a digital library with more than 60,000 free eBooks. You can see most popular books downloaded from Guttenberg website [here](http://www.gutenberg.org/ebooks/search/?sort_order=downloads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to the book text file\n",
    "gutenberg_text_link = 'https://www.gutenberg.org/files/11/11-0.txt'\n",
    "\n",
    "r = requests.get(gutenberg_text_link) # get the online book file\n",
    "r.encoding = 'utf-8' # specify the type of text encoding in the file\n",
    "book = r.text.split('***')[2] # get the part after the header\n",
    "book = book.replace(\"’\",\"'\").replace(\"“\",'\"').replace(\"”\",'\"') # replace any 'smart quotes'\n",
    "book_title = r.text[r.text.index('Title:')+7:r.text.index('Author:')-4] # find the book title\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many characters (letters, numbers, spaces, etc.) are in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split up the book by chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_list = [] # create a list to hold the chapter texts\n",
    "#chapters = pd.DataFrame() # create an empty data frame\n",
    "for chapter in book.split('CHAPTER'):\n",
    "    if len(chapter)>500: # so that we are getting actual book chapters\n",
    "        chapter_text = chapter.replace('\\r',' ').replace('\\n',' ') # delete the 'new line' characters\n",
    "        chapter_list.append(chapter_text) # add the chapter to the list\n",
    "chapters = pd.DataFrame(chapter_list, columns=['Chapter Text']) # create a data frame from the list\n",
    "chapters['Chapter'] = chapters.index+1 # add a column with the chapter number\n",
    "chapters = chapters[['Chapter', 'Chapter Text']] # reorder the columns\n",
    "chapters['Chapter Length'] = chapters['Chapter Text'].apply(len) # add a column with the length of each chapter\n",
    "chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataframe of the chapters, so we can do things like visualize their lengths (numbers of characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(chapters, x='Chapter', y='Chapter Length', title='Chapter Lengths in '+book_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the chapter lenght varies a bit, and perhaps the author wrote shorter chapters for the rising action and falling action parts of the story.\n",
    "\n",
    "### Adjectives, verbs, nouns, and proper nouns per chapter\n",
    "\n",
    "Now let's create a dataframe which tells about various characteristics of a word in the book. Description for each of the columns of the dataframe is provided below:\n",
    "\n",
    "- **text**: actual word\n",
    "- **[part of speech](https://spacy.io/api/annotation#pos-tagging)**: ADJ, VERB, NOUN, or PROPN\n",
    "- **lemma**: headword\n",
    "- **chapter**: chapter number\n",
    "\n",
    "|Part of Speech|Definition|Example|\n",
    "|-|-|-|\n",
    "|Noun|A person, place, thing, or idea|The white **rabbit** runs quickly.|\n",
    "|Pronoun|Replaces a noun|**He** runs quickly.|\n",
    "|Verb|Action|The white rabbit **runs** quickly.|\n",
    "|Adjective|Describes a noun|The **white** rabbit runs quickly.|\n",
    "|Adverb|Describes a verb|The white rabbit runs **quickly**.|\n",
    "\n",
    "Running the next cell may take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_of_speech = {'Word Count':[], 'Word List':[], 'ADJ':[], 'VERB':[], 'NOUN':[], 'PROPN':[]} # create an empty dictionary to store word counts and lists\n",
    "\n",
    "for row in chapters.iterrows(): # iterate through the dataframe\n",
    "    i = row[0]\n",
    "    chapter_text = row[1]['Chapter Text']\n",
    "    for k in parts_of_speech.keys():\n",
    "        parts_of_speech[k].append(0)\n",
    "    word_list = nlp(chapter_text) # use spacy to parse the text\n",
    "    parts_of_speech['Word List'][i] = word_list\n",
    "    parts_of_speech['Word Count'][i] = len(word_list) # get the total number of words\n",
    "    for word in word_list:\n",
    "        if word.pos_ in parts_of_speech.keys():\n",
    "            parts_of_speech[word.pos_][i] += 1\n",
    "\n",
    "for k in parts_of_speech.keys():  # add the word counts to the dataframe\n",
    "    chapters[k] = parts_of_speech[k]\n",
    "chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframe now includes counts of those [parts of speech](https://spacy.io/api/annotation#pos-tagging) by chapter. We can also calculate what percent of the words in each chapter are each of those types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters['Adjectives %'] = chapters['ADJ']/chapters['Word Count']*100\n",
    "chapters['Verbs %'] = chapters['VERB']/chapters['Word Count']*100\n",
    "chapters['Nouns %'] = chapters['NOUN']/chapters['Word Count']*100\n",
    "chapters['Proper Nouns %'] = chapters['PROPN']/chapters['Word Count']*100\n",
    "chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a visualization of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(chapters, x='Chapter', y=['Adjectives %', 'Verbs %', 'Nouns %', 'Proper Nouns %'], title='Parts of Speech in '+book_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we prefer a line graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(chapters, x='Chapter', y=['Adjectives %', 'Verbs %', 'Nouns %', 'Proper Nouns %'], title='Parts of Speech in '+book_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or visualizing the chapter lengths by word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(chapters, x='Chapter', y='Word Count', title='Chapter Lengths in '+book_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common verbs\n",
    "\n",
    "To get an idea of the most common words in the text we can look at a part of speech, verbs for example, and count their occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_type = 'VERB'\n",
    "\n",
    "list_of_words = []\n",
    "for row in chapters.iterrows():\n",
    "    word_list = row[1]['Word List']\n",
    "    for word in word_list:\n",
    "        if word.pos_ == word_type:\n",
    "            list_of_words.append(word.text)\n",
    "words_df = pd.DataFrame.from_dict(Counter(list_of_words), orient='index').reset_index().rename(columns={'index':'Word', 0:'Count'})\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the ten most common verbs are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.sort_values('Count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could then visualize the data, or compare verbs to adjectives, see which are the most common pronouns, or investigate if word usage changes from chapter to chapter.\n",
    "\n",
    "Check out the [next notebook](books-challenge.ipynb) to continue your own analysis of this or another book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Callysto.ca License](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-bottom.jpg?raw=true)](https://github.com/callysto/curriculum-notebooks/blob/master/LICENSE.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
