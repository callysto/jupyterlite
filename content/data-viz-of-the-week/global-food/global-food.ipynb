{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Callysto.ca Banner](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-top.jpg?raw=true)\n",
    "<a href=\"https://colab.research.google.com/github/callysto/jupyterlite/blob/main/content/data-viz-of-the-week/global-food/global-food.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg?sanitize=true\" width=\"123\" height=\"24\" alt=\"Open in Callysto\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callysto's Weekly Data Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Food Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended Grade levels: 9-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Click \"Cell\" and select \"Run All\".\n",
    "\n",
    "This will import the data and run all the code, so you can see this week's data visualization. Scroll back to the top after youâ€™ve run the cells.\n",
    "\n",
    "![instructions](https://github.com/callysto/data-viz-of-the-week/blob/main/images/instructions.png?raw=true)\n",
    "\n",
    "**You don't need to do any coding to view the visualizations**.\n",
    "\n",
    "The plots generated in this notebook are interactive. You can hover over and click on elements to see more information. \n",
    "\n",
    "Email contact@callysto.ca if you experience issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this Notebook\n",
    "\n",
    "Callysto's Weekly Data Visualization is a learning resource that aims to develop data literacy skills. We provide Grades 5-12 teachers and students with a data visualization, like a graph, to interpret. This companion resource walks learners through how the data visualization is created and interpreted by a data scientist. \n",
    "\n",
    "The steps of the data analysis process are listed below and applied to each weekly topic.\n",
    "\n",
    "1. Question - What are we trying to answer?\n",
    "2. Gather - Find the data source(s) you will need. \n",
    "3. Organize - Arrange the data, so that you can easily explore it. \n",
    "4. Explore - Examine the data to look for evidence to answer the question. This includes creating visualizations. \n",
    "5. Interpret - Describe what's happening in the data visualization. \n",
    "6. Communicate - Explain how the evidence answers the question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "What can we learn from fluctuations in global food prices, and what other inferences can be made based on data surrounding food?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "\n",
    "Our mission is to look at how much common foods cost in different parts of the world and over different times. Specifically, we want to compare food prices for certain food items across countries to examine which countries have high and low prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "Analyzing food item prices on a global scale holds significant importancce due to its far-reaching implications for individuals, communities, and economies. According to [this](https://cdn.dal.ca/content/dam/dalhousie/pdf/sites/agri-food/Canada%27s%20Food%20Price%20Report%202023_Digital.pdf) report on Canada's food prices, total foods increased in price by 10.3%.  Access to affordable and nutritious food is a fundamental human right, and understanding the dynamics of food prices is essential in addressing global challenges such as hunger and poverty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global food price data was collected through [Kaggle](https://www.kaggle.com/datasets/lasaljaywardena/global-food-prices-dataset?resource=download), which is sourced by the [WFP](https://www.wfp.org/) (The World Food Program). The dataset is distributed by [HDX](https://data.humdata.org/). \n",
    "\n",
    "An important thing to note in this dataset is that food prices are relative to each food item's respective country. This means that food prices are not normalized. For example, if you're looking at the prices of different food items in different countries, these prices might be influenced by various factors such as local economies, currency exchange rates, etc. Normalization could involve converting all prices to a common currency or adjusting them based on a common economic indicator, like GDP per capita, to make the comparisons more reflective of their actual cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cells below to import the libraries we need for this project. Libraries are pre-made code that make it easier to analyze our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install plotly nbformat scikit-learn pandas \n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Libaries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we're going to obtain our dataset by importing it using *pd.read_csv*. We're also going to ensure that when reading our data we enforce the column `adm1_name` to being only string values. A string, in the context of computing, is a sequence of characters, such as letters, numbers, symbols, and spaces, that is used to represent text-based information.  \n",
    "\n",
    "\n",
    "We establish this practice because, without this constraint, Python (our chosen programming language) would alert us to columns containing multiple data types upon data import. Ensuring a consistent data type for each column in Python offers a range of advantages. It guarantees data precision and integrity by averting irregularities when working with columns, ultimately enhancing the reliability of our data utilization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = {'adm1_name': str}\n",
    "global_food_prices= pd.read_csv('https://swift-yeg.cloud.cybera.ca:8080/v1/AUTH_233e84cd313945c992b4b585f7b9125d/callysto-open-data/global-food-prices.csv', dtype=data_types)\n",
    "global_food_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've obtained our data, let's take a deeper look into the data types for each column. Note, our dataset is now in a dataframe format. Essentially, think of a dataframe as a spreadsheet where we have columns representing different categories or attributes of the data, and rows representing individual records or observations. Just like a spreadsheet organizes information into rows and columns, a dataframe provides a structured format for storing and analyzing data in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_food_prices.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these datatypes make sense, such as `mp_month` and `mp_year` being integers (numbers) and `mp_price` and `mp_commoditysource` being floats (decimal point numbers). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by doing some basic analysis. Let's obtain the frequency of occurences of unique values in the `pt_name` column. In other words, it quantifies how often each distinct value appears in the specified column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_food_prices['pt_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output reveals that the category *Retail* appears the most frequently, with a count of 1,287,998 occurrences. The category *Wholesale* follows with 150,711 occurrences, while *Farm Gate* and *Producer* categories are less prevalent, having counts of 664 and 248, respectively. Globally, it appears that the majority of the world utilizes retail items, which makes sense as shopping stores have become accessible to many countries and are the primary way many individuals obtain food items in the modern-day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize\n",
    "\n",
    "Let's begin to organize our data. Generally, when we organize data we perform something called *data-cleaning*. Data cleaning, an essential step in the data preparation process, involves identifying, correcting, and handling errors, inconsistencies, and inaccuracies within a dataset. It encompasses tasks such as removing duplicate or irrelevant entries, filling in missing values, correcting inaccuracies, standardizing formats, and ensuring uniformity in data representation. The goal of data cleaning is to enhance data quality, reliability, and usability, enabling accurate analyses and insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin our data-cleaning, let's check if any of columns have *null* values (missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_food_prices.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the only column that has *null* values is `mp_commoditysource`, at a staggering 1439621. It appears that there are too many *null* values for this column to be of any importance, so let's simply drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_food_prices = global_food_prices.drop('mp_commoditysource', axis=1)\n",
    "global_food_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_food_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's change some column names to reflect their data more accurately. Specifically, we'll change the names of the columns `adm0_name` and `adm1_name` to `country` and `region`, respectively. This way, the column names will better match the kind of information they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_food_prices.rename(columns={'adm0_name': 'country', 'adm1_name': 'region'}, inplace=True)\n",
    "global_food_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've performed some basic data-cleaning, let's begin some data exploration how visualizing the top 20 most frequent foods in our dataset. *Frequency* is defined as a count of categorized data, but it is not the actual values of the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_of_food = global_food_prices['cm_name'].value_counts().nlargest(20)\n",
    "top_20 = pd.DataFrame({'cm_name': count_of_food.index, 'count': count_of_food.values})\n",
    "\n",
    "top_20_foods = px.bar(top_20, x='cm_name', y='count', title='Top 20 Foods by Highest Count', color='count', labels={\"count\":\"Count\", \"cm_name\":\"Foods\"})\n",
    "top_20_foods.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization titled *Top 20 Foods by Highest Count* highlights that the prevailing items with the highest frequency are Millet - Retail, Rice (imported) - Retail, and Maize - Retail. Remarkably, all of these food items fall under the Retail category. This observation aligns with our earlier discovery that Retail items dominate our dataset in terms of prevalence. Such a pattern offers insights into the consumer-oriented nature of the data, suggesting that retail-level transactions are the main source of food transactions, possibly reflecting consumption trends and preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's determine the highest and lowest years represented in our dataframe. We'll want this information for our following visualization after this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_year = global_food_prices['mp_year'].max()\n",
    "lowest_year = global_food_prices['mp_year'].min()\n",
    "print(f\"Highest Year: {highest_year}\")\n",
    "print(f\"Lowest Year: {lowest_year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the highest and lowest years now identified in our dataframe, let's proceed to create a comparable visualization as previously done. This visualization will highlight the top 20 food items for both the highest and lowest years, or in other words, finding the top 20 food items with the highest frequencies in the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_temp = global_food_prices[global_food_prices['mp_year'] == highest_year]\n",
    "low_temp = global_food_prices[global_food_prices['mp_year'] == lowest_year]\n",
    "\n",
    "top_20_foods_highest_year = high_temp['cm_name'].value_counts().nlargest(20)\n",
    "top_20_highest_year = pd.DataFrame({'cm_name': top_20_foods_highest_year.index, 'count': top_20_foods_highest_year.values})\n",
    "\n",
    "top_20_foods_lowest_year = low_temp['cm_name'].value_counts().nlargest(20)\n",
    "top_20_lowest_year = pd.DataFrame({'cm_name': top_20_foods_lowest_year.index, 'count': top_20_foods_lowest_year.values})\n",
    "\n",
    "high_low_fig = make_subplots(rows=2, cols=1, vertical_spacing=0.2)\n",
    "\n",
    "high_low_fig.add_trace(go.Bar(x=top_20_highest_year['cm_name'], y=top_20_highest_year['count'], name='Highest Year'), row=1, col=1)\n",
    "high_low_fig.add_trace(go.Bar(x=top_20_lowest_year['cm_name'], y=top_20_lowest_year['count'], name='Lowest Year'), row=2, col=1)\n",
    "\n",
    "high_low_fig.update_layout(title_text=f\"Top 20 Foods by Highest Count in Highest ({highest_year}) and Lowest ({lowest_year}) Years\")\n",
    "high_low_fig.update_yaxes(title=\"Count\", row=1, col=1)\n",
    "high_low_fig.update_yaxes(title=\"Count\", row=2, col=1)\n",
    "\n",
    "\n",
    "high_low_fig.update_layout(height=800)\n",
    "\n",
    "high_low_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with 2021, it appears that certain items such as *Sugar*, *Salt*, and *Oil* dominate the frequency distribution. Sugar having the highest frequency, would be defined as the *mode*, a mathematical term defining the value that appears most frequently in a given set of data. This observation aligns with expectations, given that these items often serve as foundational staples in various cuisines and diets, making them widely sought after and widely available. \n",
    "\n",
    "Examining the data for the year 1990, a stark contrast emerges as we find only three items represented: *Millet*, *Sorghum*, and *Rice*. This limited diversity could be attributed to several factors. One potential factor is that data collection practices and record-keeping back in the early 1990s might have been less comprehensive compared to contemporary times, resulting in a narrower range of documented food items. \n",
    "\n",
    "Notice how the *context* of data greatly impacts what is considered a high frequency or low frequency food item. In the year 1990, millet is considered the most frequent (mode) item in the given dataset with a count of 58. However, if we put this item into the context of the year 2021, it would be considered one of the least frequent food items. This shows us that when dealing with data looking at numbers alone doesn't show the full story - looking at how the numbers fit relative to the data helps us make sense of their significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that Millet was a common food item between the 2021 and 1990 figures. Let's filter our data on this particular food item to compare the differences in prices. To do this, we're going to filter the data on our specified year and food item. Then, we're going to retrieve the maximum price for each country as each country can have multiple prices of the same item. \n",
    "\n",
    "Similarly to before, by comparing the prices between different times, we get to see if the item has generally increased or decreased in price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for 'Millet - Retail' prices and the year 2021\n",
    "millet_retail_data_2021 = global_food_prices[\n",
    "    (global_food_prices['cm_name'] == 'Millet - Retail') &\n",
    "    (global_food_prices['mp_year'] == 2021)\n",
    "]\n",
    "\n",
    "# We're going to getting only the highest price for each country \n",
    "indices_highest_prices = millet_retail_data_2021.groupby('country')['mp_price'].idxmax()\n",
    "millet_retail_highest_prices_2021 = millet_retail_data_2021.loc[indices_highest_prices]\n",
    "millet_retail_highest_prices_2021 = millet_retail_highest_prices_2021.sort_values(by='mp_price', ascending=False)\n",
    "\n",
    "millet_plots = px.scatter(millet_retail_highest_prices_2021, x='country',y='mp_price',color='mp_price',title='Highest Retail Millet Prices in 2021',hover_data=['cur_name', 'mp_month'], labels={\"country\":\"Country\", \"mp_price\":\"Currency (Various Currencies)\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's filter for the years 1990-2000. The reason why we don't only filter on 1990 is because there are so few datapoints in the year 1990 alone. This broader time frame takes into account the relative scarcity of data points in the solitary year of 1990, ensuring a more comprehensive representation of trends and fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for 'Millet - Retail' prices and years 1990-2000\n",
    "millet_retail_data_2000 = global_food_prices[\n",
    "    (global_food_prices['cm_name'] == 'Millet - Retail') &\n",
    "    (global_food_prices['mp_year'] <= 2000)\n",
    "]\n",
    "\n",
    "# We're going to getting only the highest price for each country \n",
    "indices_highest_prices = millet_retail_data_2000.groupby('country')['mp_price'].idxmax()\n",
    "millet_retail_highest_prices_2000 = millet_retail_data_2000.loc[indices_highest_prices]\n",
    "millet_retail_highest_prices_2000 = millet_retail_highest_prices_2000.sort_values(by='mp_price', ascending=False)\n",
    "\n",
    "millet_plots = px.scatter(millet_retail_highest_prices_2000, x='country',y='mp_price',color='mp_price',title='Highest Retail Millet Prices from 1990-2000',hover_data=['cur_name', 'mp_month', 'mp_year'], labels={\"country\":\"Country\", \"mp_price\":\"Currency (Various Currencies)\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_differences = []\n",
    "\n",
    "for ind in millet_retail_highest_prices_2000.index:\n",
    "    country_name = millet_retail_highest_prices_2000.loc[ind, 'country']\n",
    "    currency_name = millet_retail_highest_prices_2000.loc[ind, 'cur_name']\n",
    "    \n",
    "    if country_name in millet_retail_highest_prices_2021['country'].values:\n",
    "        price_diff = millet_retail_highest_prices_2021.loc[millet_retail_highest_prices_2021['country'] == country_name, 'mp_price'].values[0] - millet_retail_highest_prices_2000.loc[ind, 'mp_price']\n",
    "        price_differences.append((country_name, price_diff, currency_name))\n",
    "\n",
    "print(price_differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two visualizations, we notice 3 common datapoints. Beginning with *Burkina Faso*, in 1998 the highest price of Millet was 246.5199 XOF dollars. In 2021, the price increased to 335 XOF dollars. For *Niger*, the highest price in 1998 was 312 XOF dollars. This price also increased in 2021, to 364 XOF dollars. Lastly, *Senegal*'s highest price in 2000 was 144.375 XOF. In 2021, this price also increased to 350 XOF dollars. Reflect on this output, what factors could contribute to the consistent price increase of Millet across these countries over the years?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our final section of this notebook, we are going to be comparing the progression of prices of the food items in our dataset, alongside utilizing machine-learning to potentially predict the prices of items in future years. To begin, let's list all the countries in our dataset in order to filter our data under a single country's currency. Mixing different currencies would be bad practice as many countries utilize different currencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = global_food_prices['country'].unique()\n",
    "print(f\"Countries in the dataset: \\n{all_countries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of all the different countries in our dataframe, we can visualize different trends for the prices of food items in our dataframe. In our case, let's choose Rwanda, specifically as it's a country which contains many datapoints for the machine-learning portion later on. Let's begin by visualizing the trends of the highest and lowest prices every year based on the different markets in our particular country chosen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_country = 'Rwanda'\n",
    "\n",
    "country_subset = global_food_prices[global_food_prices['country'] == user_country]\n",
    "\n",
    "indices_highest_prices = country_subset.groupby(['mp_year', 'mkt_name'])['mp_price'].idxmax()\n",
    "indices_lowest_prices = country_subset.groupby(['mp_year', 'mkt_name'])['mp_price'].idxmin()\n",
    "\n",
    "highest_prices_per_year_market = country_subset.loc[indices_highest_prices].reset_index(drop=True)\n",
    "lowest_prices_per_year_market = country_subset.loc[indices_lowest_prices].reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 60)\n",
    "\n",
    "print(\"Highest Prices per Year and Market:\")\n",
    "display(highest_prices_per_year_market)\n",
    "\n",
    "print(\"\\nLowest Prices per Year and Market:\")\n",
    "display(lowest_prices_per_year_market)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output, it appears that for the Rwandan market, the months of certain items heavily dictate the price of the item for the year. For example, *beans* and *maize* both appear as highest priced and lowest priced items. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've visualized the different food prices for items in a particular market, let's move onto the final machine-learning portion of this notebook. In the context of analyzing global food prices, machine learning provides a powerful tool to uncover patterns and relationships within large datasets, offering insights into how various factors influence price trends. By leveraging algorithms like *Linear Regression*, it becomes possible to model and predict price changes based on historical data. This enables us to identify potential drivers behind price fluctuations.\n",
    "\n",
    "To begin, we're going to list all the food items in our chosen country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output to no limit\n",
    "pd.set_option('display.max_rows', None)\n",
    "country_subset['cm_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the items above, we can select a particular item to create a model on. Generally, we want to choose items that have more data-points (the number on the right of the food item) as it serves as more fuel or \"food\" to send into our model to create accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If wanted, change the product from Beans (dry) - Retail to any product above\n",
    "# Note: An product which has a larger value is much more likely to produce an ideal result for the model\n",
    "\n",
    "product = 'Beans (dry) - Retail'\n",
    "product_subset = country_subset[country_subset['cm_name'] == product]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(product_subset['mp_price'], product_subset['mp_year'], test_size=0.2, random_state=15)\n",
    "\n",
    "X_train = X_train.values.reshape(-1, 1)\n",
    "X_test = X_test.values.reshape(-1, 1)\n",
    "y_train = y_train.values.reshape(-1, 1)\n",
    "y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"R-squared (Training Set):\", r2_train)\n",
    "print(\"R-squared (Test Set):\", r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our r-squared values outputted, we can get a better sense of how our models are doing. Generally, we want models to have a higher r-squared value from the range of 0 to 1, as it is indicative of the performance of the model. In our case, our test set has an r-squared value of 0.41, which is considered a low r-squared error value reflecting that our data is not necessarily reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_test = px.scatter(x=X_test.flatten(), y=y_test.flatten(), title=f'Predicted Prices on {product}', labels={'x': 'Year', 'y': 'Price'})\n",
    "scatter_test.add_trace(go.Scatter(x=X_test.flatten(), y=y_pred_test.flatten(), mode='lines', name='Regression Line'))\n",
    "scatter_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output above, it appears that a general upwards trend was found in our model. This makes sense with our current understandings of food inflation costs. However, with the various scattering of data-points on our model due to many outliers, it appears to be very difficult to generalize values to years. To reduce the scattering, let's just take the median-value of each year so that we have easier visualization to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_prices_per_year = product_subset.groupby('mp_year')['mp_price'].median().reset_index()\n",
    "median_prices_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_prices_per_year = product_subset.groupby('mp_year')['mp_price'].median().reset_index()\n",
    "\n",
    "X = median_prices_per_year[['mp_year']]\n",
    "y = median_prices_per_year['mp_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "median_model = LinearRegression()\n",
    "median_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = median_model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R-squared value: {r2}')\n",
    "\n",
    "prediction_df = pd.DataFrame({'mp_year': X_test['mp_year'], 'Actual Price': y_test, 'Predicted Price': y_pred})\n",
    "\n",
    "median_model_plot = px.scatter(prediction_df, y=['Actual Price', 'Predicted Price'], x='mp_year',\n",
    "                          title=f'Actual vs. Predicted Prices for {product}', labels={'value': 'Price', 'mp_year': 'Year'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the new model, it appears that our values calculated through the median costs appears to be working better. The biggest difference between *actual* and *predicted* values is in the year 2021, with the other years being fairly close to their predicted values. Nonetheless, it does appear that the model is still predicting values to be gradually increasing as years progress, indicating that without fluctuations between months, it is safe to assume prices to generally increase as years increase. \n",
    "\n",
    "However, take the data seen with a *grain of salt*. While it is generally true that prices increase as years progress, this isn't always true for all food items. As seen in the plot before, there are certain years when items decrease in price despite being a higher year. Therefore, at the end of the day, individuals have to be the ones to make smart, educated choices on the cost of food with respect to the information that is presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflect on What You See"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the following questions.\n",
    "\n",
    "1. How have rising food prices impacted your own consumption patterns and budget allocation for food?\n",
    "2. How might increasing food prices speak about income inequality and access to nutritious diets?\n",
    "3. What lessons can be drawn from historical instances of food price spikes, and how can they inform proactive measures to address future challenges related to increasing food costs?\n",
    "\n",
    "# Communicate\n",
    "\n",
    "Below are some writing prompts to help you reflect on the new information that is presented from the data. When we look at the evidence, think about what you perceive about the information. Is this perception based on what the evidence shows? If others were to view it, what perceptions might they have?\n",
    "\n",
    "- I used to think ____________________ but now I know ____________________. \n",
    "- I wish I knew more about ____________________. \n",
    "- This visualization reminds me of ____________________. \n",
    "- I really like ____________________."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Callysto.ca License](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-bottom.jpg?raw=true)](https://github.com/callysto/curriculum-notebooks/blob/master/LICENSE.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
